{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis: Movie Reviews\n",
    "\n",
    "In this notebook, supervised machine learning methods are applied on a text classification problem. This problem uses a popular dataset that contains 50,000 unique instances of movie reviews extracted from Amazon. \n",
    "\n",
    "> Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher. Learning Word Vectors for Sentiment Analysis. In Association for Computational Linguistics, pp. 142--150, Portland, Oregon, USA, June, 2011. [[Web Link]](http://www.aclweb.org/anthology/P11-1015)\n",
    "\n",
    "### Data set Information (From the attached README):\n",
    "\n",
    "The core dataset contains 50,000 reviews split evenly into 25k train and 25k test sets. The overall distribution of labels is balanced (25k pos and 25k neg). We also include an additional 50,000 unlabeled documents for unsupervised learning. \n",
    "\n",
    "In the entire collection, no more than 30 reviews are allowed for any given movie because reviews for the same movie tend to have correlated ratings. Further, the train and test sets contain a disjoint set of movies, so no significant performance is obtained by memorizing movie-unique terms and their associated with observed labels. In the labeled train/test sets, a negative review has a score <= 4 out of 10, and a positive review has a score >= 7 out of 10. Thus reviews with more neutral ratings are not included in the train/test sets. In the unsupervised set, reviews of any rating are included and there are an even number of reviews > 5 and <= 5.\n",
    "\n",
    "Due the size of the dataset, kindly head over [[here]](https://ai.stanford.edu/~amaas/data/sentiment/) to download the dataset.\n",
    "\n",
    "### Objective\n",
    "To classify a movie review as positive or negative sentimentally.\n",
    " \n",
    "### Approach\n",
    "In this practice, we will be using the **TFIDFVectorizer** module by Scikit-Learn. TFIDFVectorizer is a form of Feature Extraction whereby it transform text data into feature vectors that can be used as input for estimators. The value of a word is proportionate to the count in the corpus, adjusted inversely to the number of documents it appears in the corpus (a collection of texts). This is needed as a word that frequently appears across multiple documents / texts (e.g. we, the, I) will not be useful in drawing differences between them. \n",
    "\n",
    "### Models\n",
    "In this practice, the following classifiers are used: **Multinomial Naive-Bayes** (MNB) and **Logistic Regressor** (Log).\n",
    "\n",
    "As far as possible, default parameters will be used (ie. C, max_iter, alpha) with the exception of *random_state = 0*.\n",
    "\n",
    "#### Measures \n",
    "At the end of each scenario for each approach, the following scores will be calculated for each model: \n",
    "\n",
    " - Precision Scores\n",
    " - Recall Scores\n",
    " - Cross-validated accuracy scores for training set, and accuracy scores for test set\n",
    " \n",
    "### Conclusion \n",
    "For each model, it's classification ability is very high. For MultinomialNB, it has accuracy of 0.85424, precision score of 0.851206, and a recall score of 0.85856. In Logistic Regression, it generated a higher accuracy of 0.88012, precision score of 0.873047, and a recall score of 0.88960. In general, the Logisitic Regression performed better than the MultinomialNB model. Both models do not overfit the training data (with similar accuracies to the test set), and produced good generalised models. However, this may be attributed to the extensive set of training records for only two classes (12500 instances each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries related to importing of data, cleaning, storing, and manipulation.\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries related to text processing\n",
    "import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "# Libraries related to Machine Learning\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Other Libraries\n",
    "import time ## Used to measure the time taken for some processes (e.g. Importing, Training, Evaluating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import completed for testing dataset in 68.84991 seconds.\n",
      "Import completed for training dataset in 54.38756 seconds.\n"
     ]
    }
   ],
   "source": [
    "mypath = \"C:/Users/XXX/XXX/XXX/XXXX/XXXX/aclImdb/{}/{}\" # Masked for privacy\n",
    "\n",
    "d = {}\n",
    "for path in ['test', 'train']:\n",
    "    start = time.time()\n",
    "    for typ in ['neg', 'pos']:\n",
    "        d[\"{}_{}\".format(path, typ)] = [open(mypath.format(path, typ) + \"/\" + f, 'r', encoding = 'utf8').read() for f in os.listdir(mypath.format(path, typ)) if os.path.isfile(os.path.join(mypath.format(path, typ), f)) and f.endswith('.txt')]\n",
    "    print(\"Import completed for {}ing dataset in {:.5f} seconds.\".format(path, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe used for training purposes\n",
    "train_pos = pd.DataFrame(d['train_pos'])\n",
    "train_pos['sentiment'] = 1\n",
    "train_neg = pd.DataFrame(d['train_neg'])\n",
    "train_neg['sentiment'] = 0\n",
    "\n",
    "train_df = train_pos.append(train_neg, ignore_index = True)\n",
    "\n",
    "# Dataframe used for testing purposes\n",
    "test_pos = pd.DataFrame(d['test_pos'])\n",
    "test_pos['sentiment'] = 1\n",
    "test_neg = pd.DataFrame(d['test_neg'])\n",
    "test_neg['sentiment'] = 0\n",
    "\n",
    "test_df = test_pos.append(test_neg, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(series):\n",
    "    lst = []\n",
    "    PUNCT_TO_REMOVE = string.punctuation\n",
    "    for text in series:\n",
    "        text = unidecode.unidecode(BeautifulSoup(text, \"html.parser\").get_text(separator = \" \")) # Remove any HTML expr\n",
    "        #text = text.lower() # Not necessary to lower() as the Tfidf Vectorizer has an in-built function for doing so. \n",
    "        text = text.translate(str.maketrans('', '', PUNCT_TO_REMOVE)) # Remove all punctuations\n",
    "        lst.append(text)\n",
    "    return lst\n",
    "\n",
    "train_df[0], test_df[0] = pre_processing(train_df[0]), pre_processing(test_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[0]\n",
    "y = train_df['sentiment']\n",
    "\n",
    "\"\"\"\n",
    "Dataset Count: 25 000\n",
    "Minimum Document Frequency = 100  : Ignore terms that happened less than 100 times across the dataset\n",
    "> To remove words that are used very infrequently (e.g. mispellings, short languages, uniquely created words)\n",
    "\"\"\"\n",
    "vect = TfidfVectorizer(min_df = 100, stop_words = 'english', ngram_range = (1, 3), lowercase = True).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [MultinomialNB(), LogisticRegression(random_state = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation completed for MultinomialNB in 10.65864 seconds\n",
      "Cross-validation completed for LogisticRegression in 12.13979 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model\n",
       "LogisticRegression    0.86632\n",
       "MultinomialNB         0.84424\n",
       "Name: Accuracy, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_entries = []\n",
    "for model in models:\n",
    "    start = time.time()\n",
    "    m_name = model.__class__.__name__\n",
    "    accuracies = cross_val_score(model, vect.transform(X), y, scoring = 'accuracy', cv = 5)\n",
    "    for idx, accuracy in enumerate(accuracies):\n",
    "        cv_entries.append([m_name, idx, accuracy])\n",
    "    print(\"Cross-validation completed for {} in {:.5f} seconds\".format(m_name, time.time() - start))\n",
    "cv_dF = pd.DataFrame(cv_entries, columns = ['Model','Job','Accuracy'])\n",
    "cv_dF.groupby('Model').mean().iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed for MultinomialNB in 43.08900 seconds\n",
      "Evaluation completed for LogisticRegression in 43.59243 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.85424</td>\n",
       "      <td>0.851206</td>\n",
       "      <td>0.85856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.88012</td>\n",
       "      <td>0.873047</td>\n",
       "      <td>0.88960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score  Precision   Recall\n",
       "Model                                          \n",
       "MultinomialNB       0.85424   0.851206  0.85856\n",
       "LogisticRegression  0.88012   0.873047  0.88960"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_entries = []\n",
    "for model in models:\n",
    "    start = time.time()\n",
    "    m_name = model.__class__.__name__\n",
    "    model.fit(vect.transform(X), y)\n",
    "    score = model.score(vect.transform(test_df[0]), test_df['sentiment'])\n",
    "    precision = precision_score(test_df['sentiment'], model.predict(vect.transform(test_df[0])))\n",
    "    recall = recall_score(test_df['sentiment'], model.predict(vect.transform(test_df[0])))\n",
    "    eval_entries.append([m_name, score, precision, recall])\n",
    "    print(\"Evaluation completed for {} in {:.5f} seconds\".format(m_name, time.time() - start))\n",
    "score_dF = pd.DataFrame(eval_entries, columns = ['Model', 'Score', 'Precision', 'Recall']).set_index('Model')\n",
    "score_dF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
